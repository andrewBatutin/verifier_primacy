{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Tool Call Decision Trace\n",
    "\n",
    "Debug tool call outputs by extracting decision graphs from logits.\n",
    "\n",
    "This notebook captures logits at every generation step to:\n",
    "- Identify decision points (tool name, param names, param values)\n",
    "- Calculate confidence at each decision\n",
    "- Find the \"weakest link\" in tool call generation\n",
    "- Detect potential hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "id": "setup",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "\"\"\"Setup: Import dependencies and load model.\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model, tokenizer = load(\"mlx-community/Qwen3-4B-4bit\")\n",
    "print(\"Model loaded!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dataclasses",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:15:06.256545Z",
     "start_time": "2025-12-13T21:15:06.228031Z"
    }
   },
   "source": [
    "\"\"\"Data structures for tracing.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class DecisionPoint:\n",
    "    \"\"\"A single token decision during generation.\"\"\"\n",
    "    position: int           # Token position in output\n",
    "    token_id: int           # Selected token ID\n",
    "    token_str: str          # Decoded token string\n",
    "    decision_type: str      # \"tool_name\" | \"param_name\" | \"param_value\" | \"structure\" | \"other\"\n",
    "    prob: float             # Probability of selected token\n",
    "    alternatives: list      # Top-5 alternatives [(token_str, prob), ...]\n",
    "    entropy: float          # Distribution entropy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolCallTrace:\n",
    "    \"\"\"Complete trace of a tool call generation.\"\"\"\n",
    "    raw_output: str                           # Full generated text\n",
    "    parsed_call: dict                         # {\"name\": \"...\", \"arguments\": {...}}\n",
    "    decisions: list = field(default_factory=list)  # List of DecisionPoint\n",
    "    weakest_link: DecisionPoint = None        # Lowest confidence decision\n",
    "    total_confidence: float = 1.0             # Product of all decision probs\n",
    "\n",
    "\n",
    "print(\"Dataclasses defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataclasses defined!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "tracer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:13:45.414696Z",
     "start_time": "2025-12-13T21:13:45.407454Z"
    }
   },
   "source": [
    "\"\"\"ToolCallTracer: Generate tool calls while capturing logits.\"\"\"\n",
    "\n",
    "class ToolCallTracer:\n",
    "    \"\"\"Generate tool calls and capture full logit history.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.logit_history = []  # Captured during generation\n",
    "        self.token_history = []  # Generated tokens\n",
    "        \n",
    "    def generate_with_trace(self, prompt: str, max_tokens: int = 100, \n",
    "                           temperature: float = 0.0) -> ToolCallTrace:\n",
    "        \"\"\"Generate while capturing logits at every step.\"\"\"\n",
    "        self.logit_history = []\n",
    "        self.token_history = []\n",
    "        \n",
    "        # Encode prompt\n",
    "        tokens = mx.array(self.tokenizer.encode(prompt))\n",
    "        prompt_len = len(tokens)\n",
    "        \n",
    "        # Generate token by token\n",
    "        for _ in range(max_tokens):\n",
    "            logits = self.model(tokens[None])[0, -1, :]\n",
    "            \n",
    "            # Store logits before any modification\n",
    "            self.logit_history.append(logits)\n",
    "            \n",
    "            # Sample next token\n",
    "            if temperature == 0:\n",
    "                next_token = mx.argmax(logits).item()\n",
    "            else:\n",
    "                scaled_logits = logits / temperature\n",
    "                next_token = mx.random.categorical(scaled_logits).item()\n",
    "            \n",
    "            self.token_history.append(next_token)\n",
    "            \n",
    "            # Check for EOS\n",
    "            if next_token == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "                \n",
    "            tokens = mx.concatenate([tokens, mx.array([next_token])])\n",
    "        \n",
    "        # Decode output\n",
    "        raw_output = self.tokenizer.decode(self.token_history)\n",
    "        \n",
    "        # Parse tool call\n",
    "        parsed_call = self._parse_tool_call(raw_output)\n",
    "        \n",
    "        # Extract decision points\n",
    "        decisions = self._extract_decisions(raw_output, parsed_call)\n",
    "        \n",
    "        # Find weakest link and total confidence\n",
    "        weakest_link = None\n",
    "        total_confidence = 1.0\n",
    "        \n",
    "        for d in decisions:\n",
    "            total_confidence *= d.prob\n",
    "            if weakest_link is None or d.prob < weakest_link.prob:\n",
    "                weakest_link = d\n",
    "        \n",
    "        return ToolCallTrace(\n",
    "            raw_output=raw_output,\n",
    "            parsed_call=parsed_call,\n",
    "            decisions=decisions,\n",
    "            weakest_link=weakest_link,\n",
    "            total_confidence=total_confidence,\n",
    "        )\n",
    "    \n",
    "    def _parse_tool_call(self, text: str) -> dict:\n",
    "        \"\"\"Extract tool call from <tool_call>...</tool_call> tags.\"\"\"\n",
    "        # Try to find tool_call tags\n",
    "        match = re.search(r'<tool_call>\\s*(.+?)\\s*</tool_call>', text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(1))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        # Try to find raw JSON\n",
    "        match = re.search(r'\\{\"name\":\\s*\"([^\"]+)\".*?\"arguments\":\\s*(\\{[^}]+\\})\\}', text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return {\"name\": match.group(1), \"arguments\": json.loads(match.group(2))}\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        return {\"name\": None, \"arguments\": {}}\n",
    "    \n",
    "    def _classify_token(self, pos: int, token_str: str, raw_output: str, parsed_call: dict) -> str:\n",
    "        \"\"\"Classify token as tool_name, param_name, param_value, structure, or other.\"\"\"\n",
    "        # Get context up to this position\n",
    "        context = self.tokenizer.decode(self.token_history[:pos+1])\n",
    "        \n",
    "        # Check if in tool name\n",
    "        if parsed_call.get(\"name\"):\n",
    "            name = parsed_call[\"name\"]\n",
    "            if name in context and name not in self.tokenizer.decode(self.token_history[:pos]):\n",
    "                if token_str.strip() in name:\n",
    "                    return \"tool_name\"\n",
    "        \n",
    "        # Check if in param name\n",
    "        for param_name in parsed_call.get(\"arguments\", {}).keys():\n",
    "            if param_name in context:\n",
    "                prev_context = self.tokenizer.decode(self.token_history[:pos]) if pos > 0 else \"\"\n",
    "                if param_name not in prev_context:\n",
    "                    if token_str.strip() in param_name or param_name.startswith(token_str.strip()):\n",
    "                        return \"param_name\"\n",
    "        \n",
    "        # Check if in param value\n",
    "        for param_name, param_value in parsed_call.get(\"arguments\", {}).items():\n",
    "            param_str = str(param_value)\n",
    "            if param_str in context:\n",
    "                prev_context = self.tokenizer.decode(self.token_history[:pos]) if pos > 0 else \"\"\n",
    "                if param_str not in prev_context:\n",
    "                    if token_str.strip() in param_str:\n",
    "                        return \"param_value\"\n",
    "        \n",
    "        # Check for JSON structure tokens\n",
    "        structure_tokens = ['{', '}', '[', ']', ':', ',', '\"', '<', '>', '/']\n",
    "        if any(s in token_str for s in structure_tokens):\n",
    "            return \"structure\"\n",
    "        \n",
    "        return \"other\"\n",
    "    \n",
    "    def _extract_decisions(self, raw_output: str, parsed_call: dict) -> list:\n",
    "        \"\"\"Extract decision points from logit history.\"\"\"\n",
    "        decisions = []\n",
    "        \n",
    "        for pos, (token_id, logits) in enumerate(zip(self.token_history, self.logit_history)):\n",
    "            # Decode token\n",
    "            token_str = self.tokenizer.decode([token_id])\n",
    "            \n",
    "            # Compute probabilities\n",
    "            probs = mx.softmax(logits)\n",
    "            prob = probs[token_id].item()\n",
    "            \n",
    "            # Compute entropy\n",
    "            log_probs = mx.log(probs + 1e-10)\n",
    "            entropy = -mx.sum(probs * log_probs).item()\n",
    "            \n",
    "            # Get top-5 alternatives\n",
    "            top_indices = mx.argsort(probs)[-5:][::-1].tolist()\n",
    "            alternatives = []\n",
    "            for idx in top_indices:\n",
    "                alt_str = self.tokenizer.decode([idx])\n",
    "                alt_prob = probs[idx].item()\n",
    "                alternatives.append((alt_str, alt_prob))\n",
    "            \n",
    "            # Classify token\n",
    "            decision_type = self._classify_token(pos, token_str, raw_output, parsed_call)\n",
    "            \n",
    "            decisions.append(DecisionPoint(\n",
    "                position=pos,\n",
    "                token_id=token_id,\n",
    "                token_str=token_str,\n",
    "                decision_type=decision_type,\n",
    "                prob=prob,\n",
    "                alternatives=alternatives,\n",
    "                entropy=entropy,\n",
    "            ))\n",
    "        \n",
    "        return decisions\n",
    "\n",
    "\n",
    "print(\"ToolCallTracer defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolCallTracer defined!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "verifier",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:13:46.756966Z",
     "start_time": "2025-12-13T21:13:46.752871Z"
    }
   },
   "source": [
    "\"\"\"ToolCallVerifier: Verify tool calls using decision trace.\"\"\"\n",
    "\n",
    "class ToolCallVerifier:\n",
    "    \"\"\"Verify tool calls and detect potential issues.\"\"\"\n",
    "    \n",
    "    def __init__(self, allowed_tools: list, user_input: str = \"\"):\n",
    "        self.allowed_tools = allowed_tools\n",
    "        self.user_input = user_input.lower()\n",
    "    \n",
    "    def verify(self, trace: ToolCallTrace) -> dict:\n",
    "        \"\"\"Verify a tool call trace and return issues.\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Check if tool is allowed\n",
    "        tool_name = trace.parsed_call.get(\"name\")\n",
    "        valid_tool = tool_name in self.allowed_tools if tool_name else False\n",
    "        if not valid_tool:\n",
    "            issues.append(f\"Unknown tool: {tool_name}\")\n",
    "        \n",
    "        # Check confidence threshold\n",
    "        confidence_ok = trace.weakest_link is None or trace.weakest_link.prob > 0.5\n",
    "        if not confidence_ok:\n",
    "            issues.append(f\"Low confidence at: {trace.weakest_link.token_str!r} ({trace.weakest_link.prob:.2%})\")\n",
    "        \n",
    "        # Check for hallucination risk\n",
    "        hallucination_risk, hallucinated_values = self._check_hallucination(trace)\n",
    "        if hallucination_risk:\n",
    "            for val in hallucinated_values:\n",
    "                issues.append(f\"Potential hallucination: {val!r} not in user input\")\n",
    "        \n",
    "        # Check for low-confidence param values\n",
    "        low_conf_params = []\n",
    "        for d in trace.decisions:\n",
    "            if d.decision_type == \"param_value\" and d.prob < 0.7:\n",
    "                low_conf_params.append((d.token_str, d.prob))\n",
    "        if low_conf_params:\n",
    "            issues.append(f\"Low-confidence param values: {low_conf_params}\")\n",
    "        \n",
    "        return {\n",
    "            \"valid_tool\": valid_tool,\n",
    "            \"confidence_ok\": confidence_ok,\n",
    "            \"hallucination_risk\": hallucination_risk,\n",
    "            \"total_confidence\": trace.total_confidence,\n",
    "            \"weakest_prob\": trace.weakest_link.prob if trace.weakest_link else 1.0,\n",
    "            \"issues\": issues,\n",
    "        }\n",
    "    \n",
    "    def _check_hallucination(self, trace: ToolCallTrace) -> tuple:\n",
    "        \"\"\"Check if param values appear in user input.\"\"\"\n",
    "        if not self.user_input:\n",
    "            return False, []\n",
    "        \n",
    "        hallucinated = []\n",
    "        for param_name, param_value in trace.parsed_call.get(\"arguments\", {}).items():\n",
    "            param_str = str(param_value).lower()\n",
    "            # Skip short values that might be defaults\n",
    "            if len(param_str) < 3:\n",
    "                continue\n",
    "            if param_str not in self.user_input:\n",
    "                hallucinated.append(f\"{param_name}={param_value}\")\n",
    "        \n",
    "        return len(hallucinated) > 0, hallucinated\n",
    "\n",
    "\n",
    "print(\"ToolCallVerifier defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolCallVerifier defined!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "visualization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:13:49.243460Z",
     "start_time": "2025-12-13T21:13:49.237843Z"
    }
   },
   "source": [
    "\"\"\"Visualization: Color-coded trace display.\"\"\"\n",
    "\n",
    "def get_confidence_color(prob: float) -> str:\n",
    "    \"\"\"Get color based on confidence level.\"\"\"\n",
    "    if prob >= 0.8:\n",
    "        return \"green\"\n",
    "    elif prob >= 0.5:\n",
    "        return \"yellow\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "\n",
    "\n",
    "def print_trace(trace: ToolCallTrace):\n",
    "    \"\"\"Print trace with color-coded confidence.\"\"\"\n",
    "    console = Console()\n",
    "    \n",
    "    # Header\n",
    "    console.print(Panel(\"[bold]Tool Call Decision Trace[/bold]\", expand=False))\n",
    "    \n",
    "    # Parsed call\n",
    "    console.print(f\"\\n[bold cyan]Parsed Tool Call:[/bold cyan]\")\n",
    "    console.print(f\"  Name: {trace.parsed_call.get('name', 'N/A')}\")\n",
    "    console.print(f\"  Arguments: {trace.parsed_call.get('arguments', {})}\")\n",
    "    \n",
    "    # Summary stats\n",
    "    console.print(f\"\\n[bold cyan]Confidence Summary:[/bold cyan]\")\n",
    "    console.print(f\"  Total confidence: {trace.total_confidence:.4f}\")\n",
    "    if trace.weakest_link:\n",
    "        color = get_confidence_color(trace.weakest_link.prob)\n",
    "        console.print(f\"  Weakest link: [{color}]{trace.weakest_link.token_str!r}[/{color}] \"\n",
    "                     f\"(prob: {trace.weakest_link.prob:.2%}, type: {trace.weakest_link.decision_type})\")\n",
    "    \n",
    "    # Color-coded output\n",
    "    console.print(f\"\\n[bold cyan]Token-by-Token Output:[/bold cyan]\")\n",
    "    \n",
    "    output_text = Text()\n",
    "    for d in trace.decisions:\n",
    "        color = get_confidence_color(d.prob)\n",
    "        output_text.append(d.token_str, style=color)\n",
    "    \n",
    "    console.print(output_text)\n",
    "    \n",
    "    # Decision table\n",
    "    console.print(f\"\\n[bold cyan]Decision Points:[/bold cyan]\")\n",
    "    \n",
    "    table = Table()\n",
    "    table.add_column(\"Pos\", justify=\"right\", style=\"dim\")\n",
    "    table.add_column(\"Token\", style=\"cyan\")\n",
    "    table.add_column(\"Type\", style=\"magenta\")\n",
    "    table.add_column(\"Prob\", justify=\"right\")\n",
    "    table.add_column(\"Entropy\", justify=\"right\", style=\"dim\")\n",
    "    table.add_column(\"Top Alternatives\")\n",
    "    \n",
    "    for d in trace.decisions:\n",
    "        color = get_confidence_color(d.prob)\n",
    "        prob_str = f\"[{color}]{d.prob:.2%}[/{color}]\"\n",
    "        \n",
    "        # Format alternatives (skip the selected one)\n",
    "        alts = [f\"{t!r}:{p:.1%}\" for t, p in d.alternatives if t != d.token_str][:3]\n",
    "        alts_str = \", \".join(alts) if alts else \"-\"\n",
    "        \n",
    "        table.add_row(\n",
    "            str(d.position),\n",
    "            repr(d.token_str),\n",
    "            d.decision_type,\n",
    "            prob_str,\n",
    "            f\"{d.entropy:.2f}\",\n",
    "            alts_str,\n",
    "        )\n",
    "    \n",
    "    console.print(table)\n",
    "\n",
    "\n",
    "def print_verification(result: dict):\n",
    "    \"\"\"Print verification results.\"\"\"\n",
    "    console = Console()\n",
    "    \n",
    "    console.print(f\"\\n[bold cyan]Verification Results:[/bold cyan]\")\n",
    "    \n",
    "    status_color = \"green\" if not result[\"issues\"] else \"red\"\n",
    "    console.print(f\"  Valid tool: {'Yes' if result['valid_tool'] else 'No'}\")\n",
    "    console.print(f\"  Confidence OK: {'Yes' if result['confidence_ok'] else 'No'}\")\n",
    "    console.print(f\"  Hallucination risk: {'Yes' if result['hallucination_risk'] else 'No'}\")\n",
    "    console.print(f\"  Total confidence: {result['total_confidence']:.4f}\")\n",
    "    \n",
    "    if result[\"issues\"]:\n",
    "        console.print(f\"\\n[bold red]Issues:[/bold red]\")\n",
    "        for issue in result[\"issues\"]:\n",
    "            console.print(f\"  - {issue}\")\n",
    "    else:\n",
    "        console.print(f\"\\n[bold green]No issues found![/bold green]\")\n",
    "\n",
    "\n",
    "print(\"Visualization functions defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "sample-prompt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:18:26.480649Z",
     "start_time": "2025-12-13T21:18:26.420238Z"
    }
   },
   "source": [
    "\"\"\"Sample Prompt: Eney Assistant format with weather_forecast tool.\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"# Role\n",
    "You are **Eney** â€” a macOS Assistant built by MacPaw.\n",
    "\n",
    "# Tools\n",
    "## weather_forecast\n",
    "Get weather forecast for a location.\n",
    "Parameters:\n",
    "- location (string, required): City name\n",
    "- days (integer, optional): Number of days (1-7)\n",
    "## climate_forecast\n",
    "Get climate forecast for a region.\n",
    "Parameters:\n",
    "- location (string, required): City name\n",
    "- days (integer, optional): Number of days (1-7)\n",
    "\n",
    "\n",
    "# Response Format\n",
    "When you need to call a tool, output it in this format:\n",
    "<tool_call>{\"name\": \"tool_name\", \"arguments\": {\"param\": \"value\"}}</tool_call>\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"Is it raining in Paris?\"\n",
    "\n",
    "# Format with chat template (Qwen3 format)\n",
    "PROMPT = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{USER_MESSAGE}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<think>\n",
    "</think>\n",
    "\"\"\"\n",
    "\n",
    "ALLOWED_TOOLS = [\"weather_forecast\"]\n",
    "\n",
    "print(\"Prompt configured!\")\n",
    "print(f\"User message: {USER_MESSAGE!r}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt configured!\n",
      "User message: 'Is it raining in Paris?'\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "demo-run",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-13T21:18:28.258445Z"
    }
   },
   "source": [
    "\"\"\"Demo: Run tracer and visualize.\"\"\"\n",
    "\n",
    "# Create tracer\n",
    "tracer = ToolCallTracer(model, tokenizer)\n",
    "\n",
    "# Generate with trace\n",
    "print(\"Generating tool call...\")\n",
    "trace = tracer.generate_with_trace(PROMPT, max_tokens=100, temperature=0.0)\n",
    "\n",
    "# Print trace\n",
    "print_trace(trace)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tool call...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "demo-verify",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:16:35.364727Z",
     "start_time": "2025-12-13T21:16:35.330407Z"
    }
   },
   "source": [
    "\"\"\"Demo: Verify the tool call.\"\"\"\n",
    "\n",
    "# Create verifier\n",
    "verifier = ToolCallVerifier(ALLOWED_TOOLS, user_input=USER_MESSAGE)\n",
    "\n",
    "# Verify trace\n",
    "result = verifier.verify(trace)\n",
    "\n",
    "# Print results\n",
    "print_verification(result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;36mVerification Results:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Verification Results:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Valid tool: Yes\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Valid tool: Yes\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Confidence OK: Yes\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Confidence OK: Yes\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Hallucination risk: No\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Hallucination risk: No\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Total confidence: \u001B[1;36m0.9537\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total confidence: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9537</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;32mNo issues found!\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">No issues found!</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "analysis-temperature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:16:59.273882Z",
     "start_time": "2025-12-13T21:16:35.459955Z"
    }
   },
   "source": [
    "\"\"\"Analysis: Compare different temperatures.\"\"\"\n",
    "\n",
    "temperatures = [0.0, 0.3, 0.7]\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    trace = tracer.generate_with_trace(PROMPT, max_tokens=100, temperature=temp)\n",
    "    \n",
    "    print(f\"\\nOutput: {trace.raw_output[:200]}...\")\n",
    "    print(f\"Parsed: {trace.parsed_call}\")\n",
    "    print(f\"Total confidence: {trace.total_confidence:.4f}\")\n",
    "    if trace.weakest_link:\n",
    "        print(f\"Weakest: {trace.weakest_link.token_str!r} ({trace.weakest_link.prob:.2%})\")\n",
    "    \n",
    "    result = verifier.verify(trace)\n",
    "    print(f\"Issues: {result['issues'] if result['issues'] else 'None'}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Temperature: 0.0\n",
      "============================================================\n",
      "\n",
      "Output: <tool_call>{\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"London\", \"days\": 1}}</tool_call><|im_end|>...\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Weakest: '<tool_call>' (96.88%)\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "Temperature: 0.3\n",
      "============================================================\n",
      "\n",
      "Output: <tool_call>{\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"London\", \"days\": 1}}</tool_call><|im_end|>...\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Weakest: '<tool_call>' (96.88%)\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "Temperature: 0.7\n",
      "============================================================\n",
      "\n",
      "Output: <tool_call>{\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"London\", \"days\": 1}}</tool_call><|im_end|>...\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Weakest: '<tool_call>' (96.88%)\n",
      "Issues: None\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "analysis-prompts",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:17:51.637326Z",
     "start_time": "2025-12-13T21:16:59.290058Z"
    }
   },
   "source": [
    "\"\"\"Analysis: Compare different user prompts.\"\"\"\n",
    "\n",
    "test_prompts = [\n",
    "    \"Check the weather in London\",\n",
    "    \"What's the weather like in Tokyo?\",\n",
    "    \"Weather forecast for New York, 5 days\",\n",
    "    \"Is it raining in Paris?\",\n",
    "]\n",
    "\n",
    "for user_msg in test_prompts:\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_msg}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<think>\n",
    "</think>\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User: {user_msg}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    trace = tracer.generate_with_trace(prompt, max_tokens=100, temperature=0.0)\n",
    "    verifier = ToolCallVerifier(ALLOWED_TOOLS, user_input=user_msg)\n",
    "    result = verifier.verify(trace)\n",
    "    \n",
    "    print(f\"Parsed: {trace.parsed_call}\")\n",
    "    print(f\"Total confidence: {trace.total_confidence:.4f}\")\n",
    "    print(f\"Issues: {result['issues'] if result['issues'] else 'None'}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: Check the weather in London\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "User: What's the weather like in Tokyo?\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'Tokyo', 'days': 1}}\n",
      "Total confidence: 0.5634\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "User: Weather forecast for New York, 5 days\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'New York', 'days': 5}}\n",
      "Total confidence: 1.0000\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "User: Is it raining in Paris?\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'Paris', 'days': 1}}\n",
      "Total confidence: 0.2163\n",
      "Issues: None\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Confidence Colors**:\n",
    "   - Green: High confidence (>80%)\n",
    "   - Yellow: Medium confidence (50-80%)\n",
    "   - Red: Low confidence (<50%)\n",
    "\n",
    "2. **Decision Types**:\n",
    "   - `tool_name`: Part of the tool name\n",
    "   - `param_name`: Part of a parameter name\n",
    "   - `param_value`: Part of a parameter value\n",
    "   - `structure`: JSON/XML structure tokens\n",
    "   - `other`: Other tokens\n",
    "\n",
    "3. **Weakest Link**:\n",
    "   - The token with lowest probability indicates where the model was most uncertain\n",
    "   - Low confidence in `param_value` may indicate hallucination risk\n",
    "\n",
    "4. **Verification**:\n",
    "   - Checks tool validity, confidence threshold, and hallucination risk\n",
    "   - Param values not in user input flagged as potential hallucinations"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6baaa626049fba6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
