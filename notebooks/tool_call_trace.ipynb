{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Tool Call Decision Trace\n",
    "\n",
    "Debug tool call outputs by extracting decision graphs from logits.\n",
    "\n",
    "This notebook captures logits at every generation step to:\n",
    "- Identify decision points (tool name, param names, param values)\n",
    "- Calculate confidence at each decision\n",
    "- Find the \"weakest link\" in tool call generation\n",
    "- Detect potential hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "id": "setup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:33:08.609286Z",
     "start_time": "2025-12-13T21:33:06.744512Z"
    }
   },
   "source": [
    "\"\"\"Setup: Import dependencies and load model.\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model, tokenizer = load(\"mlx-community/Qwen3-4B-4bit\")\n",
    "print(\"Model loaded!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 9 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 194581.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "dataclasses",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:33:08.633421Z",
     "start_time": "2025-12-13T21:33:08.627299Z"
    }
   },
   "source": [
    "\"\"\"Data structures for tracing.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class DecisionPoint:\n",
    "    \"\"\"A single token decision during generation.\"\"\"\n",
    "    position: int           # Token position in output\n",
    "    token_id: int           # Selected token ID\n",
    "    token_str: str          # Decoded token string\n",
    "    decision_type: str      # \"tool_name\" | \"param_name\" | \"param_value\" | \"structure\" | \"other\"\n",
    "    prob: float             # Probability of selected token\n",
    "    alternatives: list      # Top-5 alternatives [(token_str, prob), ...]\n",
    "    entropy: float          # Distribution entropy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolCallTrace:\n",
    "    \"\"\"Complete trace of a tool call generation.\"\"\"\n",
    "    raw_output: str                           # Full generated text\n",
    "    parsed_call: dict                         # {\"name\": \"...\", \"arguments\": {...}}\n",
    "    decisions: list = field(default_factory=list)  # List of DecisionPoint\n",
    "    weakest_link: DecisionPoint = None        # Lowest confidence decision\n",
    "    total_confidence: float = 1.0             # Product of all decision probs\n",
    "\n",
    "\n",
    "print(\"Dataclasses defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataclasses defined!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "tracer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:33:08.670575Z",
     "start_time": "2025-12-13T21:33:08.663687Z"
    }
   },
   "source": [
    "\"\"\"ToolCallTracer: Generate tool calls while capturing logits.\"\"\"\n",
    "\n",
    "class ToolCallTracer:\n",
    "    \"\"\"Generate tool calls and capture full logit history.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.logit_history = []  # Captured during generation\n",
    "        self.token_history = []  # Generated tokens\n",
    "        \n",
    "    def generate_with_trace(self, prompt: str, max_tokens: int = 100, \n",
    "                           temperature: float = 0.0) -> ToolCallTrace:\n",
    "        \"\"\"Generate while capturing logits at every step.\"\"\"\n",
    "        self.logit_history = []\n",
    "        self.token_history = []\n",
    "        \n",
    "        # Encode prompt\n",
    "        tokens = mx.array(self.tokenizer.encode(prompt))\n",
    "        prompt_len = len(tokens)\n",
    "        \n",
    "        # Generate token by token\n",
    "        for _ in range(max_tokens):\n",
    "            logits = self.model(tokens[None])[0, -1, :]\n",
    "            \n",
    "            # Store logits before any modification\n",
    "            self.logit_history.append(logits)\n",
    "            \n",
    "            # Sample next token\n",
    "            if temperature == 0:\n",
    "                next_token = mx.argmax(logits).item()\n",
    "            else:\n",
    "                scaled_logits = logits / temperature\n",
    "                next_token = mx.random.categorical(scaled_logits).item()\n",
    "            \n",
    "            self.token_history.append(next_token)\n",
    "            \n",
    "            # Check for EOS\n",
    "            if next_token == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "                \n",
    "            tokens = mx.concatenate([tokens, mx.array([next_token])])\n",
    "        \n",
    "        # Decode output\n",
    "        raw_output = self.tokenizer.decode(self.token_history)\n",
    "        \n",
    "        # Parse tool call\n",
    "        parsed_call = self._parse_tool_call(raw_output)\n",
    "        \n",
    "        # Extract decision points\n",
    "        decisions = self._extract_decisions(raw_output, parsed_call)\n",
    "        \n",
    "        # Find weakest link and total confidence\n",
    "        weakest_link = None\n",
    "        total_confidence = 1.0\n",
    "        \n",
    "        for d in decisions:\n",
    "            total_confidence *= d.prob\n",
    "            if weakest_link is None or d.prob < weakest_link.prob:\n",
    "                weakest_link = d\n",
    "        \n",
    "        return ToolCallTrace(\n",
    "            raw_output=raw_output,\n",
    "            parsed_call=parsed_call,\n",
    "            decisions=decisions,\n",
    "            weakest_link=weakest_link,\n",
    "            total_confidence=total_confidence,\n",
    "        )\n",
    "    \n",
    "    def _parse_tool_call(self, text: str) -> dict:\n",
    "        \"\"\"Extract tool call from <tool_call>...</tool_call> tags.\"\"\"\n",
    "        # Try to find tool_call tags\n",
    "        match = re.search(r'<tool_call>\\s*(.+?)\\s*</tool_call>', text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(1))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        # Try to find raw JSON\n",
    "        match = re.search(r'\\{\"name\":\\s*\"([^\"]+)\".*?\"arguments\":\\s*(\\{[^}]+\\})\\}', text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return {\"name\": match.group(1), \"arguments\": json.loads(match.group(2))}\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        return {\"name\": None, \"arguments\": {}}\n",
    "    \n",
    "    def _classify_token(self, pos: int, token_str: str, raw_output: str, parsed_call: dict) -> str:\n",
    "        \"\"\"Classify token as tool_name, param_name, param_value, structure, or other.\"\"\"\n",
    "        # Get context up to this position\n",
    "        context = self.tokenizer.decode(self.token_history[:pos+1])\n",
    "        \n",
    "        # Check if in tool name\n",
    "        if parsed_call.get(\"name\"):\n",
    "            name = parsed_call[\"name\"]\n",
    "            if name in context and name not in self.tokenizer.decode(self.token_history[:pos]):\n",
    "                if token_str.strip() in name:\n",
    "                    return \"tool_name\"\n",
    "        \n",
    "        # Check if in param name\n",
    "        for param_name in parsed_call.get(\"arguments\", {}).keys():\n",
    "            if param_name in context:\n",
    "                prev_context = self.tokenizer.decode(self.token_history[:pos]) if pos > 0 else \"\"\n",
    "                if param_name not in prev_context:\n",
    "                    if token_str.strip() in param_name or param_name.startswith(token_str.strip()):\n",
    "                        return \"param_name\"\n",
    "        \n",
    "        # Check if in param value\n",
    "        for param_name, param_value in parsed_call.get(\"arguments\", {}).items():\n",
    "            param_str = str(param_value)\n",
    "            if param_str in context:\n",
    "                prev_context = self.tokenizer.decode(self.token_history[:pos]) if pos > 0 else \"\"\n",
    "                if param_str not in prev_context:\n",
    "                    if token_str.strip() in param_str:\n",
    "                        return \"param_value\"\n",
    "        \n",
    "        # Check for JSON structure tokens\n",
    "        structure_tokens = ['{', '}', '[', ']', ':', ',', '\"', '<', '>', '/']\n",
    "        if any(s in token_str for s in structure_tokens):\n",
    "            return \"structure\"\n",
    "        \n",
    "        return \"other\"\n",
    "    \n",
    "    def _extract_decisions(self, raw_output: str, parsed_call: dict) -> list:\n",
    "        \"\"\"Extract decision points from logit history.\"\"\"\n",
    "        decisions = []\n",
    "        \n",
    "        for pos, (token_id, logits) in enumerate(zip(self.token_history, self.logit_history)):\n",
    "            # Decode token\n",
    "            token_str = self.tokenizer.decode([token_id])\n",
    "            \n",
    "            # Compute probabilities\n",
    "            probs = mx.softmax(logits)\n",
    "            prob = probs[token_id].item()\n",
    "            \n",
    "            # Compute entropy\n",
    "            log_probs = mx.log(probs + 1e-10)\n",
    "            entropy = -mx.sum(probs * log_probs).item()\n",
    "            \n",
    "            # Get top-5 alternatives\n",
    "            top_indices = mx.argsort(probs)[-5:][::-1].tolist()\n",
    "            alternatives = []\n",
    "            for idx in top_indices:\n",
    "                alt_str = self.tokenizer.decode([idx])\n",
    "                alt_prob = probs[idx].item()\n",
    "                alternatives.append((alt_str, alt_prob))\n",
    "            \n",
    "            # Classify token\n",
    "            decision_type = self._classify_token(pos, token_str, raw_output, parsed_call)\n",
    "            \n",
    "            decisions.append(DecisionPoint(\n",
    "                position=pos,\n",
    "                token_id=token_id,\n",
    "                token_str=token_str,\n",
    "                decision_type=decision_type,\n",
    "                prob=prob,\n",
    "                alternatives=alternatives,\n",
    "                entropy=entropy,\n",
    "            ))\n",
    "        \n",
    "        return decisions\n",
    "\n",
    "\n",
    "print(\"ToolCallTracer defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolCallTracer defined!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "verifier",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:33:09.228283Z",
     "start_time": "2025-12-13T21:33:09.224568Z"
    }
   },
   "source": [
    "\"\"\"ToolCallVerifier: Verify tool calls using decision trace.\"\"\"\n",
    "\n",
    "class ToolCallVerifier:\n",
    "    \"\"\"Verify tool calls and detect potential issues.\"\"\"\n",
    "    \n",
    "    def __init__(self, allowed_tools: list, user_input: str = \"\"):\n",
    "        self.allowed_tools = allowed_tools\n",
    "        self.user_input = user_input.lower()\n",
    "    \n",
    "    def verify(self, trace: ToolCallTrace) -> dict:\n",
    "        \"\"\"Verify a tool call trace and return issues.\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Check if tool is allowed\n",
    "        tool_name = trace.parsed_call.get(\"name\")\n",
    "        valid_tool = tool_name in self.allowed_tools if tool_name else False\n",
    "        if not valid_tool:\n",
    "            issues.append(f\"Unknown tool: {tool_name}\")\n",
    "        \n",
    "        # Check confidence threshold\n",
    "        confidence_ok = trace.weakest_link is None or trace.weakest_link.prob > 0.5\n",
    "        if not confidence_ok:\n",
    "            issues.append(f\"Low confidence at: {trace.weakest_link.token_str!r} ({trace.weakest_link.prob:.2%})\")\n",
    "        \n",
    "        # Check for hallucination risk\n",
    "        hallucination_risk, hallucinated_values = self._check_hallucination(trace)\n",
    "        if hallucination_risk:\n",
    "            for val in hallucinated_values:\n",
    "                issues.append(f\"Potential hallucination: {val!r} not in user input\")\n",
    "        \n",
    "        # Check for low-confidence param values\n",
    "        low_conf_params = []\n",
    "        for d in trace.decisions:\n",
    "            if d.decision_type == \"param_value\" and d.prob < 0.7:\n",
    "                low_conf_params.append((d.token_str, d.prob))\n",
    "        if low_conf_params:\n",
    "            issues.append(f\"Low-confidence param values: {low_conf_params}\")\n",
    "        \n",
    "        return {\n",
    "            \"valid_tool\": valid_tool,\n",
    "            \"confidence_ok\": confidence_ok,\n",
    "            \"hallucination_risk\": hallucination_risk,\n",
    "            \"total_confidence\": trace.total_confidence,\n",
    "            \"weakest_prob\": trace.weakest_link.prob if trace.weakest_link else 1.0,\n",
    "            \"issues\": issues,\n",
    "        }\n",
    "    \n",
    "    def _check_hallucination(self, trace: ToolCallTrace) -> tuple:\n",
    "        \"\"\"Check if param values appear in user input.\"\"\"\n",
    "        if not self.user_input:\n",
    "            return False, []\n",
    "        \n",
    "        hallucinated = []\n",
    "        for param_name, param_value in trace.parsed_call.get(\"arguments\", {}).items():\n",
    "            param_str = str(param_value).lower()\n",
    "            # Skip short values that might be defaults\n",
    "            if len(param_str) < 3:\n",
    "                continue\n",
    "            if param_str not in self.user_input:\n",
    "                hallucinated.append(f\"{param_name}={param_value}\")\n",
    "        \n",
    "        return len(hallucinated) > 0, hallucinated\n",
    "\n",
    "\n",
    "print(\"ToolCallVerifier defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolCallVerifier defined!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "visualization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:33:09.712757Z",
     "start_time": "2025-12-13T21:33:09.707862Z"
    }
   },
   "source": [
    "\"\"\"Visualization: Color-coded trace display.\"\"\"\n",
    "\n",
    "def get_confidence_color(prob: float) -> str:\n",
    "    \"\"\"Get color based on confidence level.\"\"\"\n",
    "    if prob >= 0.8:\n",
    "        return \"green\"\n",
    "    elif prob >= 0.5:\n",
    "        return \"yellow\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "\n",
    "\n",
    "def print_trace(trace: ToolCallTrace):\n",
    "    \"\"\"Print trace with color-coded confidence.\"\"\"\n",
    "    console = Console()\n",
    "    \n",
    "    # Header\n",
    "    console.print(Panel(\"[bold]Tool Call Decision Trace[/bold]\", expand=False))\n",
    "    \n",
    "    # Parsed call\n",
    "    console.print(f\"\\n[bold cyan]Parsed Tool Call:[/bold cyan]\")\n",
    "    console.print(f\"  Name: {trace.parsed_call.get('name', 'N/A')}\")\n",
    "    console.print(f\"  Arguments: {trace.parsed_call.get('arguments', {})}\")\n",
    "    \n",
    "    # Summary stats\n",
    "    console.print(f\"\\n[bold cyan]Confidence Summary:[/bold cyan]\")\n",
    "    console.print(f\"  Total confidence: {trace.total_confidence:.4f}\")\n",
    "    if trace.weakest_link:\n",
    "        color = get_confidence_color(trace.weakest_link.prob)\n",
    "        console.print(f\"  Weakest link: [{color}]{trace.weakest_link.token_str!r}[/{color}] \"\n",
    "                     f\"(prob: {trace.weakest_link.prob:.2%}, type: {trace.weakest_link.decision_type})\")\n",
    "    \n",
    "    # Color-coded output\n",
    "    console.print(f\"\\n[bold cyan]Token-by-Token Output:[/bold cyan]\")\n",
    "    \n",
    "    output_text = Text()\n",
    "    for d in trace.decisions:\n",
    "        color = get_confidence_color(d.prob)\n",
    "        output_text.append(d.token_str, style=color)\n",
    "    \n",
    "    console.print(output_text)\n",
    "    \n",
    "    # Decision table\n",
    "    console.print(f\"\\n[bold cyan]Decision Points:[/bold cyan]\")\n",
    "    \n",
    "    table = Table()\n",
    "    table.add_column(\"Pos\", justify=\"right\", style=\"dim\")\n",
    "    table.add_column(\"Token\", style=\"cyan\")\n",
    "    table.add_column(\"Type\", style=\"magenta\")\n",
    "    table.add_column(\"Prob\", justify=\"right\")\n",
    "    table.add_column(\"Entropy\", justify=\"right\", style=\"dim\")\n",
    "    table.add_column(\"Top Alternatives\")\n",
    "    \n",
    "    for d in trace.decisions:\n",
    "        color = get_confidence_color(d.prob)\n",
    "        prob_str = f\"[{color}]{d.prob:.2%}[/{color}]\"\n",
    "        \n",
    "        # Format alternatives (skip the selected one)\n",
    "        alts = [f\"{t!r}:{p:.1%}\" for t, p in d.alternatives if t != d.token_str][:3]\n",
    "        alts_str = \", \".join(alts) if alts else \"-\"\n",
    "        \n",
    "        table.add_row(\n",
    "            str(d.position),\n",
    "            repr(d.token_str),\n",
    "            d.decision_type,\n",
    "            prob_str,\n",
    "            f\"{d.entropy:.2f}\",\n",
    "            alts_str,\n",
    "        )\n",
    "    \n",
    "    console.print(table)\n",
    "\n",
    "\n",
    "def print_verification(result: dict):\n",
    "    \"\"\"Print verification results.\"\"\"\n",
    "    console = Console()\n",
    "    \n",
    "    console.print(f\"\\n[bold cyan]Verification Results:[/bold cyan]\")\n",
    "    \n",
    "    status_color = \"green\" if not result[\"issues\"] else \"red\"\n",
    "    console.print(f\"  Valid tool: {'Yes' if result['valid_tool'] else 'No'}\")\n",
    "    console.print(f\"  Confidence OK: {'Yes' if result['confidence_ok'] else 'No'}\")\n",
    "    console.print(f\"  Hallucination risk: {'Yes' if result['hallucination_risk'] else 'No'}\")\n",
    "    console.print(f\"  Total confidence: {result['total_confidence']:.4f}\")\n",
    "    \n",
    "    if result[\"issues\"]:\n",
    "        console.print(f\"\\n[bold red]Issues:[/bold red]\")\n",
    "        for issue in result[\"issues\"]:\n",
    "            console.print(f\"  - {issue}\")\n",
    "    else:\n",
    "        console.print(f\"\\n[bold green]No issues found![/bold green]\")\n",
    "\n",
    "\n",
    "print(\"Visualization functions defined!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "sample-prompt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:41:14.517890Z",
     "start_time": "2025-12-13T21:41:14.509091Z"
    }
   },
   "source": [
    "\"\"\"Sample Prompt: Eney Assistant format with weather_forecast tool.\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"# Role\n",
    "You are **Eney** â€” a macOS Assistant built by MacPaw.\n",
    "\n",
    "# Tools\n",
    "## weather_forecast\n",
    "Get weather forecast for a location.\n",
    "Parameters:\n",
    "- location (string, required): City name\n",
    "- days (integer, optional): Number of days (1-7)\n",
    "## climate_forecast\n",
    "Get climate forecast for a region.\n",
    "Parameters:\n",
    "- location (string, required): City name\n",
    "- days (integer, optional): Number of days (1-7)\n",
    "\n",
    "\n",
    "# Response Format\n",
    "Select only one tool\n",
    "When you need to call a tool, output it in this format:\n",
    "<tool_call>{\"name\": \"tool_name\", \"arguments\": {\"param\": \"value\"}}</tool_call>\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"Tell Me a joke\"\n",
    "\n",
    "# Format with chat template (Qwen3 format)\n",
    "PROMPT = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{USER_MESSAGE}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<think>\n",
    "\n",
    "\n",
    "</think>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ALLOWED_TOOLS = [\"weather_forecast\"]\n",
    "\n",
    "print(\"Prompt configured!\")\n",
    "print(f\"User message: {USER_MESSAGE!r}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt configured!\n",
      "User message: 'Tell Me a joke'\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "demo-run",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:41:26.622293Z",
     "start_time": "2025-12-13T21:41:15.687936Z"
    }
   },
   "source": [
    "\"\"\"Demo: Run tracer and visualize.\"\"\"\n",
    "\n",
    "# Create tracer\n",
    "tracer = ToolCallTracer(model, tokenizer)\n",
    "\n",
    "# Generate with trace\n",
    "print(\"Generating tool call...\")\n",
    "trace = tracer.generate_with_trace(PROMPT, max_tokens=100, temperature=0.0)\n",
    "\n",
    "# Print trace\n",
    "print_trace(trace)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tool call...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001B[1mTool Call Decision Trace\u001B[0m â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"font-weight: bold\">Tool Call Decision Trace</span> â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;36mParsed Tool Call:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Parsed Tool Call:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Name: \u001B[3;35mNone\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Name: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Arguments: \u001B[1m{\u001B[0m\u001B[1m}\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Arguments: <span style=\"font-weight: bold\">{}</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;36mConfidence Summary:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Confidence Summary:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Total confidence: \u001B[1;36m0.0004\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total confidence: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0004</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Weakest link: \u001B[31m'mac'\u001B[0m \u001B[1m(\u001B[0mprob: \u001B[1;36m26.37\u001B[0m%, type: other\u001B[1m)\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Weakest link: <span style=\"color: #800000; text-decoration-color: #800000\">'mac'</span> <span style=\"font-weight: bold\">(</span>prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.37</span>%, type: other<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;36mToken-by-Token Output:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Token-by-Token Output:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[32mWhy\u001B[0m\u001B[32m did\u001B[0m\u001B[32m the\u001B[0m\u001B[33m mac\u001B[0m\u001B[32mbook\u001B[0m\u001B[33m fall\u001B[0m\u001B[32m in\u001B[0m\u001B[32m love\u001B[0m\u001B[32m with\u001B[0m\u001B[32m the\u001B[0m\u001B[32m laptop\u001B[0m\u001B[32m?\u001B[0m\u001B[32m Because\u001B[0m\u001B[32m it\u001B[0m\u001B[32m was\u001B[0m\u001B[32m a\u001B[0m\u001B[31m *\u001B[0m\u001B[33mmac\u001B[0m\u001B[32m*\u001B[0m\u001B[31m (\u001B[0m\u001B[31mmac\u001B[0m\u001B[32m)\u001B[0m\u001B[33m and\u001B[0m\u001B[32m it\u001B[0m\u001B[32m was\u001B[0m\u001B[33m *\u001B[0m\u001B[32ml\u001B[0m\u001B[33maptop\u001B[0m\u001B[32m*\u001B[0m\u001B[33m!\u001B[0m\u001B[32m ï¿½\u001B[0m\u001B[32mï¿½\u001B[0m\u001B[32m<|im_end|>\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Why did the</span><span style=\"color: #808000; text-decoration-color: #808000\"> mac</span><span style=\"color: #008000; text-decoration-color: #008000\">book</span><span style=\"color: #808000; text-decoration-color: #808000\"> fall</span><span style=\"color: #008000; text-decoration-color: #008000\"> in love with the laptop? Because it was a</span><span style=\"color: #800000; text-decoration-color: #800000\"> *</span><span style=\"color: #808000; text-decoration-color: #808000\">mac</span><span style=\"color: #008000; text-decoration-color: #008000\">*</span><span style=\"color: #800000; text-decoration-color: #800000\"> (mac</span><span style=\"color: #008000; text-decoration-color: #008000\">)</span><span style=\"color: #808000; text-decoration-color: #808000\"> and</span><span style=\"color: #008000; text-decoration-color: #008000\"> it was</span><span style=\"color: #808000; text-decoration-color: #808000\"> *</span><span style=\"color: #008000; text-decoration-color: #008000\">l</span><span style=\"color: #808000; text-decoration-color: #808000\">aptop</span><span style=\"color: #008000; text-decoration-color: #008000\">*</span><span style=\"color: #808000; text-decoration-color: #808000\">!</span><span style=\"color: #008000; text-decoration-color: #008000\"> ï¿½ï¿½&lt;|im_end|&gt;</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;36mDecision Points:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Decision Points:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001B[1m \u001B[0m\u001B[1mPos\u001B[0m\u001B[1m \u001B[0mâ”ƒ\u001B[1m \u001B[0m\u001B[1mToken       \u001B[0m\u001B[1m \u001B[0mâ”ƒ\u001B[1m \u001B[0m\u001B[1mType     \u001B[0m\u001B[1m \u001B[0mâ”ƒ\u001B[1m \u001B[0m\u001B[1m   Prob\u001B[0m\u001B[1m \u001B[0mâ”ƒ\u001B[1m \u001B[0m\u001B[1mEntropy\u001B[0m\u001B[1m \u001B[0mâ”ƒ\u001B[1m \u001B[0m\u001B[1mTop Alternatives                             \u001B[0m\u001B[1m \u001B[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  0\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'Why'       \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m96.88%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.16\u001B[0m\u001B[2m \u001B[0mâ”‚ 'Sure':2.6%, 'What':0.4%, ' Why':0.0%         â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  1\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' did'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m83.59%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.45\u001B[0m\u001B[2m \u001B[0mâ”‚ ' don':16.5%, ' didn':0.0%, ' do':0.0%        â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  2\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' the'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.00\u001B[0m\u001B[2m \u001B[0mâ”‚ ' you':0.0%, ' I':0.0%, 'the':0.0%            â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  3\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' mac'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m54.30%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   1.09\u001B[0m\u001B[2m \u001B[0mâ”‚ ' computer':37.3%, ' Mac':3.5%, ' apple':1.0% â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  4\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'book'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m82.42%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.60\u001B[0m\u001B[2m \u001B[0mâ”‚ ' book':14.4%, ' user':1.3%, ' fall':0.6%     â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  5\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' fall'     \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m57.81%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   1.67\u001B[0m\u001B[2m \u001B[0mâ”‚ ' go':14.6%, ' air':6.9%, ' Pro':5.4%         â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  6\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' in'       \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.01\u001B[0m\u001B[2m \u001B[0mâ”‚ ' off':0.0%, ' on':0.0%, ' down':0.0%         â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  7\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' love'     \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m97.66%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.12\u001B[0m\u001B[2m \u001B[0mâ”‚ ' the':2.6%, 'love':0.0%, ' Love':0.0%        â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  8\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' with'     \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.00\u001B[0m\u001B[2m \u001B[0mâ”‚ ' vá»›i':0.0%, '?':0.0%, ' avec':0.0%           â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m  9\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' the'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.00\u001B[0m\u001B[2m \u001B[0mâ”‚ ' a':0.0%, ' its':0.0%, ' Linux':0.0%         â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 10\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' laptop'   \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m92.58%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.40\u001B[0m\u001B[2m \u001B[0mâ”‚ ' windows':2.2%, ' iPhone':1.9%, ' iPad':1.3% â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 11\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'?'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.01\u001B[0m\u001B[2m \u001B[0mâ”‚ '?\\n\\n':0.1%, '?\\n':0.0%, '?\\n\\n\\n':0.0%      â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 12\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' Because'  \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.01\u001B[0m\u001B[2m \u001B[0mâ”‚ ' because':0.0%, '  \\n':0.0%, 'Because':0.0%  â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 13\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' it'       \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.01\u001B[0m\u001B[2m \u001B[0mâ”‚ ' they':0.1%, 'å®ƒ':0.0%, ' It':0.0%           â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 14\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' was'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m94.14%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.27\u001B[0m\u001B[2m \u001B[0mâ”‚ ' had':3.7%, ' couldn':1.3%, ' thought':0.2%  â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 15\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' a'        \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m92.58%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.39\u001B[0m\u001B[2m \u001B[0mâ”‚ ' always':2.8%, ' so':1.3%, ' an':1.2%        â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 16\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' *'        \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[31m37.50%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   1.66\u001B[0m\u001B[2m \u001B[0mâ”‚ ' great':22.7%, ' \"':22.7%, ' perfect':9.5%   â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 17\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'mac'       \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m54.30%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.91\u001B[0m\u001B[2m \u001B[0mâ”‚ 'Mac':42.2%, 'boot':0.5%, 'MAC':0.4%          â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 18\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'*'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.00\u001B[0m\u001B[2m \u001B[0mâ”‚ 'book':0.0%, '*t':0.0%, '*-':0.0%             â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 19\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' ('        \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[31m39.84%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   1.80\u001B[0m\u001B[2m \u001B[0mâ”‚ ' book':31.1%, 'book':12.9%, '...':7.9%       â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 20\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'mac'       \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[31m26.37%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   2.66\u001B[0m\u001B[2m \u001B[0mâ”‚ 'a':14.1%, 'apple':11.0%, 'Mac':9.7%          â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 21\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m')'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m98.44%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.08\u001B[0m\u001B[2m \u001B[0mâ”‚ 'book':0.9%, 'OS':0.4%, 'intosh':0.0%         â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 22\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' and'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m52.34%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   1.03\u001B[0m\u001B[2m \u001B[0mâ”‚ ' book':40.6%, ' in':2.3%, 'book':1.6%        â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 23\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' it'       \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m98.44%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.10\u001B[0m\u001B[2m \u001B[0mâ”‚ ' the':1.4%, ' *':0.2%, ' couldn':0.0%        â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 24\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' was'      \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m81.64%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.74\u001B[0m\u001B[2m \u001B[0mâ”‚ ' *':8.6%, ' just':3.6%, ' had':3.6%          â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 25\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' *'        \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m67.58%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.65\u001B[0m\u001B[2m \u001B[0mâ”‚ ' a':32.0%, ' in':0.1%, ' just':0.0%          â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 26\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'l'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m96.09%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.25\u001B[0m\u001B[2m \u001B[0mâ”‚ 'mac':2.3%, 'lo':0.6%, 'b':0.2%               â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 27\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'aptop'     \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m70.31%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.66\u001B[0m\u001B[2m \u001B[0mâ”‚ 'appy':29.3%, 'apt':0.5%, 'aptops':0.1%       â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 28\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'*'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m99.22%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.03\u001B[0m\u001B[2m \u001B[0mâ”‚ '*.':0.4%, '*-':0.0%, '*,':0.0%               â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 29\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'!'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[33m67.19%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.67\u001B[0m\u001B[2m \u001B[0mâ”‚ ' (':31.8%, '...':0.2%, ' in':0.2%            â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 30\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m' ï¿½'        \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚  \u001B[32m96.09%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.18\u001B[0m\u001B[2m \u001B[0mâ”‚ '<|im_end|>':0.1%, ' ğŸ˜‰':0.1%                 â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 31\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'ï¿½'         \u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mother    \u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.01\u001B[0m\u001B[2m \u001B[0mâ”‚ -                                             â”‚\n",
       "â”‚\u001B[2m \u001B[0m\u001B[2m 32\u001B[0m\u001B[2m \u001B[0mâ”‚\u001B[36m \u001B[0m\u001B[36m'<|im_end|>'\u001B[0m\u001B[36m \u001B[0mâ”‚\u001B[35m \u001B[0m\u001B[35mstructure\u001B[0m\u001B[35m \u001B[0mâ”‚ \u001B[32m100.00%\u001B[0m â”‚\u001B[2m \u001B[0m\u001B[2m   0.00\u001B[0m\u001B[2m \u001B[0mâ”‚ '\\n\\n':0.0%, '.':0.0%, '\\n':0.0%              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Pos </span>â”ƒ<span style=\"font-weight: bold\"> Token        </span>â”ƒ<span style=\"font-weight: bold\"> Type      </span>â”ƒ<span style=\"font-weight: bold\">    Prob </span>â”ƒ<span style=\"font-weight: bold\"> Entropy </span>â”ƒ<span style=\"font-weight: bold\"> Top Alternatives                              </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   0 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'Why'        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">96.88%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.16 </span>â”‚ 'Sure':2.6%, 'What':0.4%, ' Why':0.0%         â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   1 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' did'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">83.59%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.45 </span>â”‚ ' don':16.5%, ' didn':0.0%, ' do':0.0%        â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   2 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' the'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.00 </span>â”‚ ' you':0.0%, ' I':0.0%, 'the':0.0%            â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   3 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' mac'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">54.30%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    1.09 </span>â”‚ ' computer':37.3%, ' Mac':3.5%, ' apple':1.0% â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   4 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'book'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">82.42%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.60 </span>â”‚ ' book':14.4%, ' user':1.3%, ' fall':0.6%     â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   5 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' fall'      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">57.81%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    1.67 </span>â”‚ ' go':14.6%, ' air':6.9%, ' Pro':5.4%         â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   6 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' in'        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.01 </span>â”‚ ' off':0.0%, ' on':0.0%, ' down':0.0%         â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   7 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' love'      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">97.66%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.12 </span>â”‚ ' the':2.6%, 'love':0.0%, ' Love':0.0%        â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   8 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' with'      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.00 </span>â”‚ ' vá»›i':0.0%, '?':0.0%, ' avec':0.0%           â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   9 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' the'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.00 </span>â”‚ ' a':0.0%, ' its':0.0%, ' Linux':0.0%         â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  10 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' laptop'    </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">92.58%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.40 </span>â”‚ ' windows':2.2%, ' iPhone':1.9%, ' iPad':1.3% â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  11 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> '?'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.01 </span>â”‚ '?\\n\\n':0.1%, '?\\n':0.0%, '?\\n\\n\\n':0.0%      â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  12 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' Because'   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.01 </span>â”‚ ' because':0.0%, '  \\n':0.0%, 'Because':0.0%  â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  13 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' it'        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.01 </span>â”‚ ' they':0.1%, 'å®ƒ':0.0%, ' It':0.0%           â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  14 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' was'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">94.14%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.27 </span>â”‚ ' had':3.7%, ' couldn':1.3%, ' thought':0.2%  â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  15 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' a'         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">92.58%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.39 </span>â”‚ ' always':2.8%, ' so':1.3%, ' an':1.2%        â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  16 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' *'         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #800000; text-decoration-color: #800000\">37.50%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    1.66 </span>â”‚ ' great':22.7%, ' \"':22.7%, ' perfect':9.5%   â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  17 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'mac'        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">54.30%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.91 </span>â”‚ 'Mac':42.2%, 'boot':0.5%, 'MAC':0.4%          â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  18 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> '*'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.00 </span>â”‚ 'book':0.0%, '*t':0.0%, '*-':0.0%             â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  19 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' ('         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #800000; text-decoration-color: #800000\">39.84%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    1.80 </span>â”‚ ' book':31.1%, 'book':12.9%, '...':7.9%       â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  20 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'mac'        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #800000; text-decoration-color: #800000\">26.37%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    2.66 </span>â”‚ 'a':14.1%, 'apple':11.0%, 'Mac':9.7%          â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  21 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ')'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">98.44%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.08 </span>â”‚ 'book':0.9%, 'OS':0.4%, 'intosh':0.0%         â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  22 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' and'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">52.34%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    1.03 </span>â”‚ ' book':40.6%, ' in':2.3%, 'book':1.6%        â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  23 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' it'        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">98.44%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.10 </span>â”‚ ' the':1.4%, ' *':0.2%, ' couldn':0.0%        â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  24 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' was'       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">81.64%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.74 </span>â”‚ ' *':8.6%, ' just':3.6%, ' had':3.6%          â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  25 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' *'         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">67.58%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.65 </span>â”‚ ' a':32.0%, ' in':0.1%, ' just':0.0%          â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  26 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'l'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">96.09%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.25 </span>â”‚ 'mac':2.3%, 'lo':0.6%, 'b':0.2%               â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  27 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'aptop'      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">70.31%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.66 </span>â”‚ 'appy':29.3%, 'apt':0.5%, 'aptops':0.1%       â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  28 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> '*'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">99.22%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.03 </span>â”‚ '*.':0.4%, '*-':0.0%, '*,':0.0%               â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  29 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> '!'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #808000; text-decoration-color: #808000\">67.19%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.67 </span>â”‚ ' (':31.8%, '...':0.2%, ' in':0.2%            â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  30 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> ' ï¿½'         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚  <span style=\"color: #008000; text-decoration-color: #008000\">96.09%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.18 </span>â”‚ '&lt;|im_end|&gt;':0.1%, ' ğŸ˜‰':0.1%                 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  31 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 'ï¿½'          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> other     </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.01 </span>â”‚ -                                             â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  32 </span>â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> '&lt;|im_end|&gt;' </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> structure </span>â”‚ <span style=\"color: #008000; text-decoration-color: #008000\">100.00%</span> â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    0.00 </span>â”‚ '\\n\\n':0.0%, '.':0.0%, '\\n':0.0%              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "demo-verify",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:41:26.840881Z",
     "start_time": "2025-12-13T21:41:26.832729Z"
    }
   },
   "source": [
    "\"\"\"Demo: Verify the tool call.\"\"\"\n",
    "\n",
    "# Create verifier\n",
    "verifier = ToolCallVerifier(ALLOWED_TOOLS, user_input=USER_MESSAGE)\n",
    "\n",
    "# Verify trace\n",
    "result = verifier.verify(trace)\n",
    "\n",
    "# Print results\n",
    "print_verification(result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;36mVerification Results:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Verification Results:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Valid tool: No\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Valid tool: No\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Confidence OK: No\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Confidence OK: No\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Hallucination risk: No\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Hallucination risk: No\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  Total confidence: \u001B[1;36m0.0004\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total confidence: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0004</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;31mIssues:\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Issues:</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  - Unknown tool: \u001B[3;35mNone\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Unknown tool: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "  - Low confidence at: \u001B[32m'mac'\u001B[0m \u001B[1m(\u001B[0m\u001B[1;36m26.37\u001B[0m%\u001B[1m)\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Low confidence at: <span style=\"color: #008000; text-decoration-color: #008000\">'mac'</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.37</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "analysis-temperature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:16:59.273882Z",
     "start_time": "2025-12-13T21:16:35.459955Z"
    }
   },
   "source": [
    "\"\"\"Analysis: Compare different temperatures.\"\"\"\n",
    "\n",
    "temperatures = [0.0, 0.3, 0.7]\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    trace = tracer.generate_with_trace(PROMPT, max_tokens=100, temperature=temp)\n",
    "    \n",
    "    print(f\"\\nOutput: {trace.raw_output[:200]}...\")\n",
    "    print(f\"Parsed: {trace.parsed_call}\")\n",
    "    print(f\"Total confidence: {trace.total_confidence:.4f}\")\n",
    "    if trace.weakest_link:\n",
    "        print(f\"Weakest: {trace.weakest_link.token_str!r} ({trace.weakest_link.prob:.2%})\")\n",
    "    \n",
    "    result = verifier.verify(trace)\n",
    "    print(f\"Issues: {result['issues'] if result['issues'] else 'None'}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Temperature: 0.0\n",
      "============================================================\n",
      "\n",
      "Output: <tool_call>{\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"London\", \"days\": 1}}</tool_call><|im_end|>...\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Weakest: '<tool_call>' (96.88%)\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "Temperature: 0.3\n",
      "============================================================\n",
      "\n",
      "Output: <tool_call>{\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"London\", \"days\": 1}}</tool_call><|im_end|>...\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Weakest: '<tool_call>' (96.88%)\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "Temperature: 0.7\n",
      "============================================================\n",
      "\n",
      "Output: <tool_call>{\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"London\", \"days\": 1}}</tool_call><|im_end|>...\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Weakest: '<tool_call>' (96.88%)\n",
      "Issues: None\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "analysis-prompts",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T21:17:51.637326Z",
     "start_time": "2025-12-13T21:16:59.290058Z"
    }
   },
   "source": [
    "\"\"\"Analysis: Compare different user prompts.\"\"\"\n",
    "\n",
    "test_prompts = [\n",
    "    \"Check the weather in London\",\n",
    "    \"What's the weather like in Tokyo?\",\n",
    "    \"Weather forecast for New York, 5 days\",\n",
    "    \"Is it raining in Paris?\",\n",
    "]\n",
    "\n",
    "for user_msg in test_prompts:\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_msg}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<think>\n",
    "</think>\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User: {user_msg}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    trace = tracer.generate_with_trace(prompt, max_tokens=100, temperature=0.0)\n",
    "    verifier = ToolCallVerifier(ALLOWED_TOOLS, user_input=user_msg)\n",
    "    result = verifier.verify(trace)\n",
    "    \n",
    "    print(f\"Parsed: {trace.parsed_call}\")\n",
    "    print(f\"Total confidence: {trace.total_confidence:.4f}\")\n",
    "    print(f\"Issues: {result['issues'] if result['issues'] else 'None'}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: Check the weather in London\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'London', 'days': 1}}\n",
      "Total confidence: 0.9537\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "User: What's the weather like in Tokyo?\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'Tokyo', 'days': 1}}\n",
      "Total confidence: 0.5634\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "User: Weather forecast for New York, 5 days\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'New York', 'days': 5}}\n",
      "Total confidence: 1.0000\n",
      "Issues: None\n",
      "\n",
      "============================================================\n",
      "User: Is it raining in Paris?\n",
      "============================================================\n",
      "Parsed: {'name': 'weather_forecast', 'arguments': {'location': 'Paris', 'days': 1}}\n",
      "Total confidence: 0.2163\n",
      "Issues: None\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Confidence Colors**:\n",
    "   - Green: High confidence (>80%)\n",
    "   - Yellow: Medium confidence (50-80%)\n",
    "   - Red: Low confidence (<50%)\n",
    "\n",
    "2. **Decision Types**:\n",
    "   - `tool_name`: Part of the tool name\n",
    "   - `param_name`: Part of a parameter name\n",
    "   - `param_value`: Part of a parameter value\n",
    "   - `structure`: JSON/XML structure tokens\n",
    "   - `other`: Other tokens\n",
    "\n",
    "3. **Weakest Link**:\n",
    "   - The token with lowest probability indicates where the model was most uncertain\n",
    "   - Low confidence in `param_value` may indicate hallucination risk\n",
    "\n",
    "4. **Verification**:\n",
    "   - Checks tool validity, confidence threshold, and hallucination risk\n",
    "   - Param values not in user input flagged as potential hallucinations"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6baaa626049fba6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
